<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script
      id="Cookiebot"
      src="https://consent.cookiebot.com/uc.js"
      data-cbid="6c49deb2-db0b-4966-a687-b375f14b226d"
      data-blockingmode="auto"
      type="text/javascript"
    ></script>

    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans|Raleway:300,400"
      rel="stylesheet"
    />
    <link rel="stylesheet" type="text/css" href="../index.css" />
    <link
      rel="icon"
      type="image/x-icon"
      href="../resources/images/navbarLogo.png"
    />
    <title>Developer Productivity</title>
  </head>
  <body>
    <!--Site header-->
    <header>
      <!--Navigation bar-->
      <nav class="navOtherPages">
        <ul class="orange">
          <li id="navLogo">
            <a href="../index.html"
              ><img src="../resources/images/navbarLogo.png" class="stickyLogo"
            /></a>
          </li>
          <li id="navHomeIcon">
            <a href="../index.html"
              ><img src="../resources/images/Homeicon.png" class="home-icon"
            /></a>
          </li>
          <li>
            <a href="../about.html" class="nav-link"><strong>About</strong></a>
          </li>
          <li>
            <a href="../article-index.html" class="nav-link"
              ><strong>Articles</strong></a
            >
          </li>
        </ul>
      </nav>
    </header>
    <!--Page title-->
    <section class="titleOther">
      <h1>Measuring Internally Matters</h1>
    </section>
    <!--Sub-heading-->
    <section>
      <h2 class="contents-heading">
        From Developer Productivity to Developer Experienc
      </h2>
      <!--Main content-->
      <figure>
        <img
          src="../resources/images/metrics/pexels-olia-danilevich-4974915.jpg"
          alt="Man sitting at desk with 2 computer screens"
          class="large-image"
        />
        <figcaption>
          Photo by Olia Danilevich on
          <a
            href="https://www.pexels.com/photo/man-sitting-in-front-of-three-computers-4974915/"
            target="_blank"
            >Pexels.com</a
          >
        </figcaption>
      </figure>

      <h3>Productivity > Predictability</h3>
      <p>
        I recently spent time with an Engineering Manager at an organisation
        that seems to want to<a href="./metrics_1.html">
          measure all the wrong things</a
        >. They find themselves in constant battles to commit to dates when
        (usually poorly-defined) work will be complete.
      </p>

      <p>
        I’ve said it before, and I’ll say it again. If the majority of
        interactions between Product and Engineering are focused on “when”
        rather than “why”, “what” or “how”, it’s a clear sign of a low-trust
        environment.
        <a
          href="https://rework.withgoogle.com/print/guides/5721312655835136/"
          target="_blank"
          >Google's Project Aristotle</a
        >
        demonstrated that the number one characteristic of a high-performing
        team is Psychological Safety, where team members feel safe to take risks
        and be vulnerable. You need to solve for trust before you can hope for
        improvements.
      </p>
      <h3>Misguided Measurements</h3>
      <p>
        There’s nothing wrong with
        <a href="./panda_2.html"
          >looking to manage customer’s expectations around when work will be
          delivered</a
        >. However, prizing predictability over productivity dooms an effort and
        an organisation to failure. This is particularly true when success is
        ill-defined, or requirements keep changing. Perhaps the most egregious
        recent public failure of date-driven development of recent times was the
        <a
          href="https://businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf"
          target="_blank"
          >initial launch of healthcare.gov</a
        >
        alongside the Affordable Care Act in the US.
      </p>
      <p>
        The most important measure that can be applied to any software
        development effort is
        <a href="./panda_1.html">whether it is achieving its intended outcome</a
        >.
      </p>
      <p>
        When Elon Musk took over Twitter in 2022,
        <a
          href="https://slate.com/technology/2022/11/elon-musk-twitter-code-fixation.html"
          >he seemed to be fixated on developer activity</a
        >. Since the takeover, Twitter has become a byword for
        <a
          href="https://www.theguardian.com/technology/2023/jan/29/tears-blunders-and-chaos-inside-elon-musk-twitter"
          >how not to manage strong engineering teams</a
        >.
      </p>
      <aside>"Never mistake activity for achievement" John Wooden</aside>
      <h3>Laggards vs Leaders</h3>
      <p>
        Measuring outcomes takes time, focus and patience. These are lagging
        metrics for the success of the team and are vital for the team to
        deliver to customer needs more effectively. There are also leading
        metrics that can be used to identify high-performing teams. Leading
        metrics will help you understand that teams are doing the right thing.
        Lagging metrics will assure you they’re solving the right problems.
      </p>
      <h3>Exploring DORA</h3>
      <p>
        People have been trying to find a successful way of measuring developer
        productivity for as long as people have been developing software. The
        first set of metrics that showed strong correlation between team
        performance and team behaviours were the DORA metrics published in 2014
        by
        <a href="https://dora.dev" target="_blank"
          >DevOps Research and Assessment</a
        >.
      </p>
      <p>
        The DORA metrics were developed by Dr. Nicole Forsgren, Jez Humble, and
        Gene Kim. I first came across them when reading their book
        <a
          href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations-ebook/dp/B07B9F83WM/"
          target="_blank"
          >Accelerate</a
        >
        a few years ago. The group publishes the
        <a
          href="https://cloud.google.com/devops/state-of-devops"
          target="_blank"
          >State of DevOps</a
        >
        report each year.
      </p>
      <p>
        The DORA metrics have four core measures of developer productivity, all
        focused on quantitative metrics
      </p>
      <ul>
        <li>
          <strong>Delivery lead time</strong>: the amount of time it takes for a
          commit to reach a customer
        </li>
        <li>
          <strong>Deployment frequency</strong>: how frequently the team
          releases software to production
        </li>
        <li>
          <strong>Mean time to recover (MTTR)</strong>: the amount of time it
          takes to respond to a service incident
        </li>
        <li>
          <strong>Change failure rate</strong>: the % of deployments that result
          in a service incident or outage
        </li>
      </ul>
      <p>
        The first two of these measures help give insights into the team’s
        efficiency. The latter two offer insights into the stability of its
        software.
      </p>
      <p>
        In 2021, the DORA team extended DORA to look at Reliability as a
        standalone measure. Before this, reliability was assessed using MTTR and
        Change Failure Rate. Reliability is now defined separately as a measure
        for how well the software meets user expectations, using availability
        and performance as proxy measures.
      </p>
      <figure>
        <img
          src="../resources/images/metrics/Screenshot 2023-05-12 at 22.09.59.png"
          class="large-image"
          alt="DORA metrics"
        />
        <figcaption>
          Dora Metrics. Source:
          <a
            href="https://cloud.google.com/devops/state-of-devops/"
            target="_blank"
            >Google State of DevOps Report 2022</a
          >
        </figcaption>
      </figure>
      <p>
        To achieve a short delivery lead time and a high level of deployment
        frequency, high-performing teams divide their work into thin slices,
        delivering small incremental code changes frequently. By delivering
        small changes frequently, the teams manage deployment risk effectively.
        They have few, if any, outages, and can recover quickly in the case of a
        production issue.
      </p>
      <p>
        Nothing will make your organisation faster than reducing batch size.
      </p>
      <p>
        Delivery lead time can be defined in different ways. Some organisations
        use it to measure the time elapsed between a customer request and a
        change in production. Others measure from when a commit hits a
        production system to when that change gets deployed to a customer. Still
        others measure from when a commit is made in a lower, development
        environment to when it is released to production.
      </p>
      <p>
        There are pros and cons to each of these approaches. I would say that
        the most appropriate one varies by organisation and by scenario rather
        than there being a hard and fast rule.
      </p>
      <p>
        In an environment with a high level of automation test coverage and full
        CI/CD, measuring the time from code commit in a lower environment to
        production release may be beneficial. In less mature environments, it
        may be valuable to step back and look at the entire value stream
        end-to-end, thus measuring the time from idea to adoption. Value stream
        mapping is a fantastic exercise for finding and fixing wrinkles in the
        ideation, development and deployment processes of an organisation. Value
        stream mapping is strongly recommended if you lack insights into parts
        of the development process, or where there are issues that prevent rapid
        deployment of software.
      </p>
      <h3>Heading for SPACE</h3>
      <p>
        Dr Nicola Forsgren was also involved in the creation of
        <a href="https://queue.acm.org/detail.cfm?id=3454124" target="_blank"
          >the SPACE framework</a
        >
        in 2021. SPACE expands the lens through which organisations can measure
        developer productivity, including broader measures of the health of
        their software development practices.
      </p>
      <p>
        SPACE introduces qualitative measures that enhance the quantitative
        focus of DORA metrics, including developer perception of teamwork, their
        own productivity and job satisfaction.
      </p>
      <p>SPACE measures five dimensions of Developer Productivity:</p>
      <ul>
        <li>
          <strong>Satisfaction and wellbeing</strong>, measuring fulfilment and
          happiness at work. This is usually captured via survey data on
          employee satisfaction, tooling efficacy and factors leading to or
          relating to burnout.
        </li>
        <li>
          <strong>Performance:</strong> did the software achieve the desired
          outcome? This can be measured through usage, customer satisfaction
          surveys, customer adoption, incidence of bugs or failures, etc.
        </li>
        <li>
          <strong>Activity:</strong> while it’s important not to conflate
          activity with productivity, some indications of developer activity can
          be useful when used in conjunction with the other measures, e.g.,
          number of pull requests, number of bugs created, contributions to
          documentation and design specs, use of CI/CD, etc.
        </li>
        <li>
          <strong>Communication and Collaboration:</strong> Effective teams rely
          on each other so that the entire team can succeed. Teams with stronger
          communication patterns and higher levels of alignment are more likely
          to be successful. Metrics that can be used to measure communication
          and collaboration include the volume and discoverability of technical
          documentation, the speed at which work can be integrated, onboarding
          time for new members, and the quality of reviews completed.
          Organisational network analysis can reveal the links and strength of
          the relationships within and between teams.
        </li>
        <li>
          <strong>Efficiency and Flow:</strong> Minimising delays and handoffs
          will increase developer productivity. Measures here include how easily
          can developers move code through the value stream the levels of
          interruptions do they face.
        </li>
      </ul>
      <figure>
        <img
          src="../resources/images/metrics/forsgren1.svg"
          alt="SPACE framework"
          class="large-image"
        />
        <figcaption>
          Sample SPACE metrics. Source:
          <a href="https://queue.acm.org/detail.cfm?id=3454124" target="_blank"
            >The SPACE of Developer Productivity</a
          >
        </figcaption>
      </figure>
      <h3>A New Hope?</h3>
      <p>
        Earlier this month, the team behind SPACE returned with
        <a href="https://queue.acm.org/detail.cfm?id=3595878" target="_blank"
          >an updated view of what drives developer productivity</a
        >, recommending a developer-centric approach focused on developer
        experience (DevEx). They recommend homing in on the lived experience of
        developers and removing the frictions or barriers to flow experienced by
        engineers.
      </p>
      <figure>
        <img
          src="../resources/images/metrics/3elementsDX.svg"
          alt="Elements of DevEx"
          class="large-image"
        />
        <figcaption>
          The three elements of Developer Experience. Source:
          <a href="https://queue.acm.org/detail.cfm?id=3595878" target="_blank"
            >DevEx: What Actually Drives Productivity</a
          >
        </figcaption>
      </figure>
      <p>
        As with SPACE, the framework looks beyond quantitative measures and
        tools to inspect issues that impact developers in the round, such as
        psychological safety and having clear goals. Companies with high-quality
        work environments are more productive than those with poor DevEx. They
        recommend using survey data to measure developer perception and
        experience in three key areas:
      </p>
      <ul>
        <li>
          <strong>Flow state</strong>: Flow occurs when developers are working
          on tasks that require controlled attention (LINK) without
          interruption. Reducing meetings and ensuring developers have blocked
          off non-interruptible time can help deliver a flow state.
        </li>
        <li>
          <strong>Feedback loops</strong>: Shortening feedback loops enhances
          developer experience. We already know that small batch sizes are
          beneficial for managing software development as it increases the
          frequency of customer feedback. DevEx goes beyond this, looking at
          ways of speeding up code reviews and testing so that developers
          receive feedback on their work as quickly as possible throughout the
          development process.
        </li>
        <li>
          <strong
            ><a
              href="https://www.interaction-design.org/literature/topics/cognitive-load"
              target="_blank"
              >Cognitive load</a
            ></strong
          >: Reducing switching costs and enabling developers to reach a flow
          state when working has a real impact on developer productivity. By
          reducing task complexity and cognitive load, organisations can free
          developers to do their best work.
        </li>
      </ul>
    </section>

    <footer class="orange">
      <div>
        <a href="https://twitter.com/iamakeogh" target="_blank"
          ><img
            src="../resources/images/Twitter social icons - rounded square - blue.png"
            class="logo"
            alt="Follow me on Twitter"
        /></a>
        <a href="https://github.com/andykanu?tab=repositories" target="_blank"
          ><img
            src="../resources/images/GitHub-Mark-Light-120px-plus.png"
            alt="Github logo"
            class="logo"
        /></a>
        <a href="https://www.linkedin.com/in/andrew-keogh-ie/" target="_blank"
          ><img
            src="../resources/images/LI-In-Bug.png"
            alt="LinkedIn logo"
            class="logo"
        /></a>
        <a href="../rss.xml"
          ><img
            src="https://wp-assets.rss.com/blog/wp-content/uploads/2019/10/10111557/social_style_3_rss-512-1.png"
            alt="RSS"
            target="_blank"
            class="logo"
          />
        </a>
      </div>
      <div class="copyright" id="orange">&copy; 2023 Octoshark Ltd</div>
    </footer>
    <div id="disqus_thread"></div>
    <script>
      /**
       *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
       *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */

      var disqus_config = function () {
        this.page.url = "https://octoshark.net/articles/metrics_2.html"; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "metrics_2"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
      };

      (function () {
        // DON'T EDIT BELOW THIS LINE
        var d = document,
          s = d.createElement("script");
        s.src = "https://octoshark.disqus.com/embed.js";
        s.setAttribute("data-timestamp", +new Date());
        (d.head || d.body).appendChild(s);
      })();
    </script>
    <noscript
      >Please enable JavaScript to view the
      <a href="https://disqus.com/?ref_noscript"
        >comments powered by Disqus.</a
      ></noscript
    >
  </body>
  <script src="../resources/scripts/articleLevelWhiteHomeIcon.js"></script>
</html>
